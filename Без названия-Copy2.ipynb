{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from soreva_metrics import calculate_metrics, macro_averaged_mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symps = [\n",
    "         'artifact',\n",
    "         'calcified cyst',\n",
    "         'calcified vessels',\n",
    "         'calcinates_benign',\n",
    "         'calcinates_malignant',\n",
    "         'fibrocystic_breast_changes',\n",
    "         'lymphonodus',\n",
    "         'mass_benign',\n",
    "         'mass_malignant',\n",
    "         'nipple',\n",
    "         'papilloma',\n",
    "         'pectoral muscle',\n",
    "         'skin_thickening',\n",
    "         'other'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_features(breast):\n",
    "    \n",
    "    predictors = {}\n",
    "\n",
    "    \n",
    "# ---------------------------------\n",
    "# Every model and view\n",
    "\n",
    "\n",
    "    for key in ['patient_id', 'laterality', 'tissue_density_predicted', 'cancer_probability_predicted']:\n",
    "        predictors[key] = breast[key]\n",
    "    \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for modl in [1, 2, 3]:\n",
    "            for symp in symps:\n",
    "                for agg in ['min', 'max', 'mean', 'median', 'sum', 'count']:\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "                    \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for modl in [1, 2, 3]:\n",
    "            for symp in symps:\n",
    "                for agg in ['min', 'max', 'mean', 'median', 'sum']:\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "                    \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for modl in [1, 2, 3]:\n",
    "            for symp in symps:\n",
    "                for agg in ['min', 'max', 'mean', 'median', 'sum']:\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "\n",
    "                \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        \n",
    "        for modl in [1, 2, 3]:\n",
    "        \n",
    "            for symp in symps:\n",
    "            \n",
    "                objs_probs = [obj['probability'] for obj in breast[view] if symp in obj['object_type'] \n",
    "                              and obj['model_number'] == modl]\n",
    "                \n",
    "                objs_coords = [obj['coordinates'] for obj in breast[view] if symp in obj[\"object_type\"]\n",
    "                               and obj['model_number'] == modl]\n",
    "            \n",
    "                if objs_probs:\n",
    "                    \n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_min'] = np.min(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_max'] = np.max(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_mean'] = np.mean(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_median'] = np.median(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_sum'] = np.sum(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_count'] = len(objs_probs)\n",
    "                    \n",
    "                    objs_squares = [(cord[2] - cord[0])*(cord[3] - cord[1]) for cord in objs_coords]\n",
    "                    \n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_min'] = np.min(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_max'] = np.max(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_mean'] = np.mean(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_median'] = np.median(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_sum'] = np.sum(objs_squares)\n",
    "                    \n",
    "                    objs_probs_squares = [sq*prob for sq, prob in zip(objs_squares, objs_probs)]\n",
    "                    \n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_min'] = np.min(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_max'] = np.max(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_mean'] = np.mean(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_median'] = np.median(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_sum'] = np.sum(objs_probs_squares)\n",
    "                    \n",
    "        \n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_basic_features(breast):\n",
    "    \n",
    "    predictors = {}\n",
    "\n",
    "    \n",
    "# ---------------------------------\n",
    "# Every model and view\n",
    "\n",
    "\n",
    "    for key in ['patient_id', 'laterality', 'tissue_density_predicted', 'cancer_probability_predicted']:\n",
    "        predictors[key] = breast[key]\n",
    "    \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for modl in [1, 2, 3]:\n",
    "            for symp in symps:\n",
    "                for agg in ['min', 'max', 'mean', 'median', 'sum', 'count']:\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "                    \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for modl in [1, 2, 3]:\n",
    "            for symp in symps:\n",
    "                for agg in ['min', 'max', 'mean', 'median', 'sum']:\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "                    \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for modl in [1, 2, 3]:\n",
    "            for symp in symps:\n",
    "                for agg in ['min', 'max', 'mean', 'median', 'sum']:\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "                    \n",
    "#     for view in [\"CC\", \"MLO\"]:\n",
    "#         for modl in [1, 2, 3]:\n",
    "#             for symp in symps:\n",
    "#                 for agg in ['min', 'max', 'mean', 'median']:\n",
    "#                     predictors['xx_'+view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "#                     predictors['yy_'+view+'_'+str(modl)+'_'+symp+'_'+agg] = 0.0\n",
    "\n",
    "                \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        \n",
    "        for modl in [1, 2, 3]:\n",
    "        \n",
    "            for symp in symps:\n",
    "            \n",
    "                objs_probs = [obj['probability'] for obj in breast[view] if symp in obj['object_type'] \n",
    "                              and obj['model_number'] == modl]\n",
    "                \n",
    "                objs_coords = [obj['coordinates'] for obj in breast[view] if symp in obj[\"object_type\"]\n",
    "                               and obj['model_number'] == modl]\n",
    "            \n",
    "                if objs_probs:\n",
    "                    \n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_min'] = np.min(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_max'] = np.max(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_mean'] = np.mean(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_median'] = np.median(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_sum'] = np.sum(objs_probs)\n",
    "                    predictors[view+'_'+str(modl)+'_'+symp+'_count'] = len(objs_probs)\n",
    "                    \n",
    "                    objs_squares = [(cord[2] - cord[0])*(cord[3] - cord[1]) for cord in objs_coords]\n",
    "                    \n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_min'] = np.min(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_max'] = np.max(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_mean'] = np.mean(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_median'] = np.median(objs_squares)\n",
    "                    predictors['square_'+view+'_'+str(modl)+'_'+symp+'_sum'] = np.sum(objs_squares)\n",
    "                    \n",
    "                    objs_probs_squares = [sq*prob for sq, prob in zip(objs_squares, objs_probs)]\n",
    "                    \n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_min'] = np.min(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_max'] = np.max(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_mean'] = np.mean(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_median'] = np.median(objs_probs_squares)\n",
    "                    predictors['prob_square_'+view+'_'+str(modl)+'_'+symp+'_sum'] = np.sum(objs_probs_squares)\n",
    "    \n",
    "# ----------------------------------\n",
    "# All models\n",
    "\n",
    "\n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for symp in symps:\n",
    "            for agg in ['min', 'max', 'mean', 'median', 'sum', 'count']:\n",
    "                predictors[view+'_'+symp+'_'+agg] = 0.0\n",
    "                \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for symp in symps:\n",
    "            for agg in ['min', 'max', 'mean', 'median']:\n",
    "                predictors['square_'+view+'_'+symp+'_'+agg] = 0.0\n",
    "                    \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        for symp in symps:\n",
    "            for agg in ['min', 'max', 'mean', 'median', 'sum']:\n",
    "                predictors['prob_square_'+view+'_'+symp+'_'+agg] = 0.0\n",
    "                \n",
    "    for view in [\"CC\", \"MLO\"]:\n",
    "        \n",
    "        for symp in symps:\n",
    "        \n",
    "            objs_probs = [obj['probability'] for obj in breast[view] if symp in obj['object_type']]\n",
    "            \n",
    "            objs_coords = [obj['coordinates'] for obj in breast[view] if symp in obj[\"object_type\"]]\n",
    "        \n",
    "            if objs_probs:\n",
    "                \n",
    "                predictors[view+'_'+symp+'_min'] = np.min(objs_probs)\n",
    "                predictors[view+'_'+symp+'_max'] = np.max(objs_probs)\n",
    "                predictors[view+'_'+symp+'_mean'] = np.mean(objs_probs)\n",
    "                predictors[view+'_'+symp+'_median'] = np.median(objs_probs)\n",
    "                predictors[view+'_'+symp+'_sum'] = np.sum(objs_probs)\n",
    "                predictors[view+'_'+symp+'_count'] = len(objs_probs)\n",
    "                \n",
    "                objs_squares = [(cord[2] - cord[0])*(cord[3] - cord[1]) for cord in objs_coords]\n",
    "                \n",
    "                predictors['square_'+view+'_'+symp+'_min'] = np.min(objs_squares)\n",
    "                predictors['square_'+view+'_'+symp+'_max'] = np.max(objs_squares)\n",
    "                predictors['square_'+view+'_'+symp+'_mean'] = np.mean(objs_squares)\n",
    "                predictors['square_'+view+'_'+symp+'_median'] = np.median(objs_squares)\n",
    "                \n",
    "                objs_probs_squares = [cord*prob for cord, prob in zip(objs_squares, objs_probs)]\n",
    "                \n",
    "                predictors['prob_square_'+view+'_'+symp+'_min'] = np.min(objs_probs_squares)\n",
    "                predictors['prob_square_'+view+'_'+symp+'_max'] = np.max(objs_probs_squares)\n",
    "                predictors['prob_square_'+view+'_'+symp+'_mean'] = np.mean(objs_probs_squares)\n",
    "                predictors['prob_square_'+view+'_'+symp+'_median'] = np.median(objs_probs_squares)\n",
    "                predictors['prob_square_'+view+'_'+symp+'_sum'] = np.sum(objs_probs_squares)\n",
    "                \n",
    "# ----------------------------------\n",
    "# All models and views\n",
    "\n",
    "\n",
    "    for symp in symps:\n",
    "        for agg in ['min', 'max', 'mean', 'median', 'sum', 'count']:\n",
    "            predictors[symp+'_'+agg] = 0.0\n",
    "                \n",
    "    for symp in symps:\n",
    "        for agg in ['min', 'max', 'mean', 'median']:\n",
    "            predictors['square_'+symp+'_'+agg] = 0.0\n",
    "                    \n",
    "    for symp in symps:\n",
    "        for agg in ['min', 'max', 'mean', 'median', 'sum']:\n",
    "            predictors['prob_square_'+symp+'_'+agg] = 0.0\n",
    "        \n",
    "    for symp in symps:\n",
    "        \n",
    "        objs_probs = [obj['probability'] for obj in breast['CC'] if symp in obj['object_type']]\n",
    "        [objs_probs.append(obj['probability']) for obj in breast['MLO'] if symp in obj['object_type']]\n",
    "        \n",
    "        objs_coords = [obj['coordinates'] for obj in breast['CC'] if symp in obj['object_type']]\n",
    "        [objs_coords.append(obj['coordinates']) for obj in breast['MLO'] if symp in obj['object_type']]\n",
    "    \n",
    "        if objs_probs:\n",
    "            \n",
    "            predictors[symp+'_min'] = np.min(objs_probs)\n",
    "            predictors[symp+'_max'] = np.max(objs_probs)\n",
    "            predictors[symp+'_mean'] = np.mean(objs_probs)\n",
    "            predictors[symp+'_median'] = np.median(objs_probs)\n",
    "            predictors[symp+'_sum'] = np.sum(objs_probs)\n",
    "            predictors[symp+'_count'] = len(objs_probs)\n",
    "            \n",
    "            objs_squares = [(cord[2] - cord[0])*(cord[3] - cord[1]) for cord in objs_coords]\n",
    "            \n",
    "            predictors['square_'+symp+'_min'] = np.min(objs_squares)\n",
    "            predictors['square_'+symp+'_max'] = np.max(objs_squares)\n",
    "            predictors['square_'+symp+'_mean'] = np.mean(objs_squares)\n",
    "            predictors['square_'+symp+'_median'] = np.median(objs_squares)\n",
    "            \n",
    "            objs_probs_squares = [cord*prob for cord, prob in zip(objs_squares, objs_probs)]\n",
    "            \n",
    "            predictors['prob_square_'+symp+'_min'] = np.min(objs_probs_squares)\n",
    "            predictors['prob_square_'+symp+'_max'] = np.max(objs_probs_squares)\n",
    "            predictors['prob_square_'+symp+'_mean'] = np.mean(objs_probs_squares)\n",
    "            predictors['prob_square_'+symp+'_median'] = np.median(objs_probs_squares)\n",
    "            predictors['prob_square_'+symp+'_sum'] = np.sum(objs_probs_squares)\n",
    "                \n",
    "# ----------------------------------\n",
    "# All models and views and symps\n",
    "\n",
    "\n",
    "#     for agg in ['min', 'max', 'mean', 'median', 'sum', 'count']:\n",
    "#         predictors[agg] = 0.0\n",
    "                \n",
    "#     for agg in ['min', 'max', 'mean', 'median']:\n",
    "#         predictors['square_'+agg] = 0.0\n",
    "                    \n",
    "#     for agg in ['min', 'max', 'mean', 'median', 'sum']:\n",
    "#         predictors['prob_square_'+agg] = 0.0\n",
    "        \n",
    "#     objs_probs = [obj['probability'] for obj in breast['CC']]\n",
    "#     [objs_probs.append(obj['probability']) for obj in breast['MLO']]\n",
    "    \n",
    "#     objs_coords = [obj['coordinates'] for obj in breast['CC']]\n",
    "#     [objs_coords.append(obj['coordinates']) for obj in breast['MLO']]\n",
    "    \n",
    "#     if objs_probs:\n",
    "        \n",
    "#         predictors['min'] = np.min(objs_probs)\n",
    "#         predictors['max'] = np.max(objs_probs)\n",
    "#         predictors['mean'] = np.mean(objs_probs)\n",
    "#         predictors['median'] = np.median(objs_probs)\n",
    "#         predictors['sum'] = np.sum(objs_probs)\n",
    "#         predictors['count'] = len(objs_probs)\n",
    "        \n",
    "#         objs_squares = [(cord[2] - cord[0])*(cord[3] - cord[1]) for cord in objs_coords]\n",
    "        \n",
    "#         predictors['square_'+'min'] = np.min(objs_squares)\n",
    "#         predictors['square_'+'max'] = np.max(objs_squares)\n",
    "#         predictors['square_'+'mean'] = np.mean(objs_squares)\n",
    "#         predictors['square_'+'median'] = np.median(objs_squares)\n",
    "        \n",
    "#         objs_probs_squares = [cord*prob for cord, prob in zip(objs_squares, objs_probs)]\n",
    "        \n",
    "#         predictors['prob_square_'+'min'] = np.min(objs_probs_squares)\n",
    "#         predictors['prob_square_'+'max'] = np.max(objs_probs_squares)\n",
    "#         predictors['prob_square_'+'mean'] = np.mean(objs_probs_squares)\n",
    "#         predictors['prob_square_'+'median'] = np.median(objs_probs_squares)\n",
    "#         predictors['prob_square_'+'sum'] = np.sum(objs_probs_squares)\n",
    "        \n",
    "    return predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4063/4063 [00:33<00:00, 122.87it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_train/data_train.json\", \"r\") as fin:\n",
    "    data_train = json.load(fin)\n",
    "\n",
    "targets_train = pd.read_csv(\"data_train/targets_train.csv\", index_col=0)\n",
    "\n",
    "predictors = {}\n",
    "for key, value in tqdm(data_train.items()):\n",
    "    predictors[key] = extract_basic_features(value)\n",
    "\n",
    "df_train = pd.DataFrame.from_dict(predictors, orient=\"index\")\n",
    "df_train = pd.merge(df_train, targets_train, left_index=True, right_index=True)\n",
    "\n",
    "df_train.loc[df_train.laterality == 'L', 'laterality'] = 0\n",
    "df_train.loc[df_train.laterality == 'R', 'laterality'] = 1\n",
    "df_train['laterality'] = df_train['laterality'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_columns = df_train[df_train.columns[1:-1]].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[['another_'+x for x in train_columns]] = 0\n",
    "\n",
    "# for i in tqdm(range(df_train.shape[0])):\n",
    "    \n",
    "#     pid = df_train.patient_id.iloc[i]\n",
    "#     lat = df_train.laterality.iloc[i]\n",
    "    \n",
    "#     try:\n",
    "    \n",
    "#         df_train.loc[(df_train.patient_id == pid)\n",
    "#                      &(df_train.laterality == lat), ['another_'+x for x in train_columns]] \\\n",
    "#         = df_train.loc[(df_train.patient_id == pid)\n",
    "#                        &(df_train.laterality != lat), train_columns].iloc[0].values\n",
    "        \n",
    "#     except:\n",
    "        \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(['patient_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4663/4663 [00:38<00:00, 121.95it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_test/data_test.json\", \"r\") as fin:\n",
    "    data_test = json.load(fin)\n",
    "\n",
    "predictors_test = {}\n",
    "for key, value in tqdm(data_test.items()):\n",
    "    predictors_test[key] = extract_basic_features(value)\n",
    "\n",
    "df_test = pd.DataFrame.from_dict(predictors_test, orient=\"index\")\n",
    "\n",
    "df_test.loc[df_test.laterality == 'L', 'laterality'] = 0\n",
    "df_test.loc[df_test.laterality == 'R', 'laterality'] = 1\n",
    "df_test['laterality'] = df_test['laterality'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(['patient_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test[['another_'+x for x in train_columns]] = 0\n",
    "\n",
    "# for i in tqdm(range(df_test.shape[0])):\n",
    "    \n",
    "#     pid = df_test.patient_id.iloc[i]\n",
    "#     lat = df_test.laterality.iloc[i]\n",
    "    \n",
    "#     try:\n",
    "    \n",
    "#         df_test.loc[(df_test.patient_id == pid)\n",
    "#                      &(df_test.laterality == lat), ['another_'+x for x in train_columns]] \\\n",
    "#         = df_test.loc[(df_test.patient_id == pid)\n",
    "#                        &(df_test.laterality != lat), train_columns].iloc[0].values\n",
    "        \n",
    "#     except:\n",
    "        \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_best = pd.read_csv('sub_18.csv')\n",
    "df_test['BiRads'] = sub_best['BiRads'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4663, 1977)\n",
      "(4663,)\n"
     ]
    }
   ],
   "source": [
    "X_test_train = df_test.drop(['BiRads'], axis=1).copy()\n",
    "y_test_train = df_test['BiRads'].copy()\n",
    "print(X_test_train.shape)\n",
    "print(y_test_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4063, 1977)\n",
      "(4063,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train.drop(['BiRads'], axis=1)\n",
    "y = df_train['BiRads']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8726, 1977)\n",
      "(8726,)\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([X, X_test_train], ignore_index=True)\n",
    "y = pd.concat([y, y_test_train], ignore_index=True)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_train.drop(['BiRads'], axis=1)\n",
    "# y = df_train['BiRads']\n",
    "# print(X.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRads\n",
       "1    2427\n",
       "2    3594\n",
       "3    1138\n",
       "4    1347\n",
       "5     220\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reset_index().groupby('BiRads').index.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GradientBoostingClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # ExtraTreesClassifier, GradientBoostingClassifier, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.11211\n",
      "0:\tlearn: 1.5272254\ttest: 1.5321866\tbest: 1.5321866 (0)\ttotal: 875ms\tremaining: 14m 34s\n",
      "100:\tlearn: 0.8108903\ttest: 1.0099800\tbest: 1.0099800 (100)\ttotal: 22.2s\tremaining: 3m 17s\n",
      "200:\tlearn: 0.6439491\ttest: 0.9859121\tbest: 0.9859121 (200)\ttotal: 44.1s\tremaining: 2m 55s\n",
      "300:\tlearn: 0.5306945\ttest: 0.9784904\tbest: 0.9778257 (283)\ttotal: 1m 6s\tremaining: 2m 33s\n",
      "400:\tlearn: 0.4454548\ttest: 0.9762596\tbest: 0.9761281 (369)\ttotal: 1m 26s\tremaining: 2m 9s\n",
      "500:\tlearn: 0.3765231\ttest: 0.9782063\tbest: 0.9761281 (369)\ttotal: 1m 47s\tremaining: 1m 47s\n",
      "600:\tlearn: 0.3220637\ttest: 0.9804570\tbest: 0.9761281 (369)\ttotal: 2m 8s\tremaining: 1m 25s\n",
      "Stopped by overfitting detector  (250 iterations wait)\n",
      "\n",
      "bestTest = 0.9761281019\n",
      "bestIteration = 369\n",
      "\n",
      "Shrink model to first 370 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1cf0b3e20>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(loss_function='MultiClass',\n",
    "#                            auto_class_weights='Balanced',\n",
    "#                            l2_leaf_reg=5, iterations=2000,\n",
    "#                            class_weights=[1, 1, 1.5, 1.5, 1.5],\n",
    "#                            random_strength=10, bagging_temperature=10,\n",
    "                           early_stopping_rounds=250, verbose=100)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val),\n",
    "          cat_features=['laterality', \n",
    "#                         'another_laterality'\n",
    "                       ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.112255\n",
      "0:\tlearn: 1.5194657\ttest: 1.5414109\tbest: 1.5414109 (0)\ttotal: 457ms\tremaining: 7m 36s\n",
      "100:\tlearn: 0.7718494\ttest: 1.1620439\tbest: 1.1617769 (97)\ttotal: 21.6s\tremaining: 3m 12s\n",
      "200:\tlearn: 0.6145409\ttest: 1.1604287\tbest: 1.1593271 (163)\ttotal: 43.1s\tremaining: 2m 51s\n",
      "300:\tlearn: 0.5049591\ttest: 1.1691391\tbest: 1.1593271 (163)\ttotal: 1m 5s\tremaining: 2m 32s\n",
      "400:\tlearn: 0.4264132\ttest: 1.1750044\tbest: 1.1593271 (163)\ttotal: 1m 29s\tremaining: 2m 13s\n",
      "Stopped by overfitting detector  (250 iterations wait)\n",
      "\n",
      "bestTest = 1.159327142\n",
      "bestIteration = 163\n",
      "\n",
      "Shrink model to first 164 iterations.\n",
      "0.11077184010625116\n",
      "Learning rate set to 0.112255\n",
      "0:\tlearn: 1.5124835\ttest: 1.5404678\tbest: 1.5404678 (0)\ttotal: 401ms\tremaining: 6m 40s\n",
      "100:\tlearn: 0.7816704\ttest: 1.1292742\tbest: 1.1288509 (99)\ttotal: 23.5s\tremaining: 3m 28s\n",
      "200:\tlearn: 0.6196086\ttest: 1.1145031\tbest: 1.1142724 (186)\ttotal: 45.6s\tremaining: 3m 1s\n",
      "300:\tlearn: 0.5088359\ttest: 1.1105940\tbest: 1.1068042 (269)\ttotal: 1m 7s\tremaining: 2m 37s\n",
      "400:\tlearn: 0.4288663\ttest: 1.1089005\tbest: 1.1068042 (269)\ttotal: 1m 29s\tremaining: 2m 14s\n",
      "500:\tlearn: 0.3638434\ttest: 1.1170794\tbest: 1.1068042 (269)\ttotal: 1m 52s\tremaining: 1m 52s\n",
      "Stopped by overfitting detector  (250 iterations wait)\n",
      "\n",
      "bestTest = 1.106804166\n",
      "bestIteration = 269\n",
      "\n",
      "Shrink model to first 270 iterations.\n",
      "0.23495193023355074\n",
      "Learning rate set to 0.112255\n",
      "0:\tlearn: 1.5176882\ttest: 1.5370692\tbest: 1.5370692 (0)\ttotal: 375ms\tremaining: 6m 14s\n",
      "100:\tlearn: 0.7932263\ttest: 1.1040497\tbest: 1.1040497 (100)\ttotal: 22.8s\tremaining: 3m 23s\n",
      "200:\tlearn: 0.6337928\ttest: 1.0897755\tbest: 1.0897755 (200)\ttotal: 43.5s\tremaining: 2m 53s\n",
      "300:\tlearn: 0.5269834\ttest: 1.0870455\tbest: 1.0860720 (298)\ttotal: 1m 3s\tremaining: 2m 28s\n",
      "400:\tlearn: 0.4406469\ttest: 1.0832934\tbest: 1.0811968 (381)\ttotal: 1m 24s\tremaining: 2m 6s\n",
      "500:\tlearn: 0.3744009\ttest: 1.0866370\tbest: 1.0811968 (381)\ttotal: 1m 45s\tremaining: 1m 44s\n",
      "600:\tlearn: 0.3202198\ttest: 1.0888916\tbest: 1.0811968 (381)\ttotal: 2m 5s\tremaining: 1m 23s\n",
      "Stopped by overfitting detector  (250 iterations wait)\n",
      "\n",
      "bestTest = 1.081196781\n",
      "bestIteration = 381\n",
      "\n",
      "Shrink model to first 382 iterations.\n",
      "0.2169285394336737\n",
      "Learning rate set to 0.112255\n",
      "0:\tlearn: 1.5311845\ttest: 1.5145544\tbest: 1.5145544 (0)\ttotal: 371ms\tremaining: 6m 11s\n",
      "100:\tlearn: 0.8613577\ttest: 0.8785640\tbest: 0.8785640 (100)\ttotal: 21.1s\tremaining: 3m 7s\n",
      "200:\tlearn: 0.6813349\ttest: 0.8381028\tbest: 0.8381028 (200)\ttotal: 43s\tremaining: 2m 50s\n",
      "300:\tlearn: 0.5631194\ttest: 0.8222150\tbest: 0.8222150 (300)\ttotal: 1m 3s\tremaining: 2m 27s\n",
      "400:\tlearn: 0.4698726\ttest: 0.8141347\tbest: 0.8137345 (398)\ttotal: 1m 23s\tremaining: 2m 5s\n",
      "500:\tlearn: 0.3962135\ttest: 0.8100033\tbest: 0.8095329 (494)\ttotal: 1m 45s\tremaining: 1m 44s\n",
      "600:\tlearn: 0.3386831\ttest: 0.8047179\tbest: 0.8043595 (599)\ttotal: 2m 6s\tremaining: 1m 24s\n",
      "700:\tlearn: 0.2919061\ttest: 0.8026219\tbest: 0.8025121 (690)\ttotal: 2m 27s\tremaining: 1m 2s\n",
      "800:\tlearn: 0.2506976\ttest: 0.7971911\tbest: 0.7968347 (795)\ttotal: 2m 49s\tremaining: 42.1s\n",
      "900:\tlearn: 0.2174451\ttest: 0.7956226\tbest: 0.7947705 (825)\ttotal: 3m 11s\tremaining: 21.1s\n",
      "999:\tlearn: 0.1905822\ttest: 0.7936856\tbest: 0.7934605 (956)\ttotal: 3m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7934605484\n",
      "bestIteration = 956\n",
      "\n",
      "Shrink model to first 957 iterations.\n",
      "0.24908688880286084\n",
      "Learning rate set to 0.112255\n",
      "0:\tlearn: 1.5321822\ttest: 1.5127496\tbest: 1.5127496 (0)\ttotal: 367ms\tremaining: 6m 7s\n",
      "100:\tlearn: 0.8620845\ttest: 0.8496580\tbest: 0.8496580 (100)\ttotal: 23.3s\tremaining: 3m 27s\n",
      "200:\tlearn: 0.6860516\ttest: 0.8124694\tbest: 0.8124694 (200)\ttotal: 45.5s\tremaining: 3m\n",
      "300:\tlearn: 0.5644979\ttest: 0.7972647\tbest: 0.7972647 (300)\ttotal: 1m 7s\tremaining: 2m 36s\n",
      "400:\tlearn: 0.4711369\ttest: 0.7921501\tbest: 0.7915850 (381)\ttotal: 1m 29s\tremaining: 2m 12s\n",
      "500:\tlearn: 0.3964110\ttest: 0.7894173\tbest: 0.7891626 (497)\ttotal: 1m 51s\tremaining: 1m 50s\n",
      "600:\tlearn: 0.3393356\ttest: 0.7871919\tbest: 0.7861089 (589)\ttotal: 2m 13s\tremaining: 1m 28s\n",
      "700:\tlearn: 0.2915677\ttest: 0.7812699\tbest: 0.7811865 (691)\ttotal: 2m 34s\tremaining: 1m 5s\n",
      "800:\tlearn: 0.2495327\ttest: 0.7825220\tbest: 0.7809735 (701)\ttotal: 2m 57s\tremaining: 44s\n",
      "900:\tlearn: 0.2155258\ttest: 0.7818365\tbest: 0.7809735 (701)\ttotal: 3m 18s\tremaining: 21.8s\n",
      "Stopped by overfitting detector  (250 iterations wait)\n",
      "\n",
      "bestTest = 0.7809734852\n",
      "bestIteration = 701\n",
      "\n",
      "Shrink model to first 702 iterations.\n",
      "0.29280597517400203\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for train_index, test_index in StratifiedKFold(n_splits=5).split(X, y):\n",
    "    \n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    \n",
    "    X_val, y_val = X.iloc[test_index], y.iloc[test_index]\n",
    "    \n",
    "    model = CatBoostClassifier(loss_function='MultiClass',\n",
    "                               early_stopping_rounds=250,\n",
    "                               verbose=100)\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=(X_val, y_val),\n",
    "              cat_features=['laterality'])\n",
    "    \n",
    "    print(calculate_metrics(y_val.values, model.predict(X_val)))\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = []\n",
    "\n",
    "# for i in range(5):\n",
    "    \n",
    "#     test_temp = df_test.sample(2000)\n",
    "    \n",
    "#     X = df_train.drop(['patient_id', 'BiRads'], axis=1)\n",
    "#     y = df_train['BiRads']\n",
    "    \n",
    "#     X = pd.concat([X, test_temp.drop(['patient_id', 'BiRads'], axis=1)], ignore_index=True)\n",
    "#     y = pd.concat([y, test_temp['BiRads']], ignore_index=True)\n",
    "#     print(X.shape)\n",
    "#     print(y.shape)\n",
    "    \n",
    "#     model = CatBoostClassifier(loss_function='MultiClass',\n",
    "#                                early_stopping_rounds=250,\n",
    "#                                verbose=100)\n",
    "\n",
    "#     model.fit(X_train, y_train, eval_set=(X_val, y_val),\n",
    "#               cat_features=['laterality'])\n",
    "    \n",
    "#     models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4663, 1978)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((X_val.shape[0], 5))\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    preds += model.predict_proba(X_val) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729551067541522"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:, 4].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = []\n",
    "\n",
    "for pred in preds:\n",
    "    \n",
    "    max_pred = np.where(pred == pred.max())[0][0]\n",
    "    \n",
    "    if pred[4] > 0.005:\n",
    "        preds_.append(5)\n",
    "    \n",
    "    elif pred[3] > 0.01:\n",
    "        preds_.append(4)\n",
    "    \n",
    "    elif pred[2] > 0.015:\n",
    "        preds_.append(3)\n",
    "    \n",
    "    else:\n",
    "        preds_.append(max_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4329156247610729"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(y_val.values, np.array(preds_)) + 0.25*macro_averaged_mean_absolute_error(y_val.values, np.array(preds_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22253386534882363"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.25*macro_averaged_mean_absolute_error(y_val.values, np.array(preds_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2103817594122493"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(y_val.values, np.array(preds_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29280597517400203"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_metrics(y_val.values, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((df_test.shape[0], 5))\n",
    "\n",
    "for model in models:\n",
    "    preds += model.predict_proba(df_test.drop(['BiRads'], axis=1)) / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.predict_proba(df_test.drop(['BiRads'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     preds[:, i] = (preds[:, i] - preds[:, i].min()) / (preds[:, i].max() - preds[:, i].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729551067541522"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:, 4].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = []\n",
    "\n",
    "for pred in preds:\n",
    "    \n",
    "    max_pred = np.where(pred == pred.max())[0][0]\n",
    "    \n",
    "    if pred[4] > 0.5:\n",
    "        preds_.append(5)\n",
    "    \n",
    "    elif pred[3] > 0.5:\n",
    "        preds_.append(4)\n",
    "    \n",
    "    elif pred[2] > 0.5:\n",
    "        preds_.append(3)\n",
    "        \n",
    "    elif pred[1] > 0.5:\n",
    "        preds_.append(2)\n",
    "    \n",
    "    elif pred[0] > 0.5:\n",
    "        preds_.append(1)\n",
    "    \n",
    "    else:\n",
    "#         preds_.append(3)\n",
    "        preds_.append(max_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_ = model.predict(df_test.drop(['BiRads'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['BiRads'] = preds_\n",
    "sub['best'] = pd.read_csv('sub_18.csv')['BiRads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRads\n",
       "1     989\n",
       "2    1389\n",
       "3     825\n",
       "4    1249\n",
       "5     211\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.groupby('BiRads').id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best\n",
       "1     937\n",
       "2    1175\n",
       "3    1034\n",
       "4    1303\n",
       "5     214\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.groupby('best').id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.BiRads != sub.best].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id', 'BiRads']].to_csv('sub_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fimp = np.zeros((df_train.shape[1]-1))\n",
    "\n",
    "# for model in models:\n",
    "    \n",
    "#     fimp += model.get_feature_importance() / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame()\n",
    "feature_importance['feature'] = X.columns\n",
    "feature_importance['importance'] = model.get_feature_importance()\n",
    "# feature_importance['importance'] = fimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>prob_square_MLO_1_calcinates_benign_max</td>\n",
       "      <td>0.719360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>square_MLO_1_calcinates_benign_sum</td>\n",
       "      <td>0.716224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cancer_probability_predicted</td>\n",
       "      <td>0.698121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>prob_square_CC_3_calcinates_benign_min</td>\n",
       "      <td>0.584782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>MLO_2_mass_malignant_min</td>\n",
       "      <td>0.569182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>CC_1_mass_benign_count</td>\n",
       "      <td>0.004604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>square_MLO_1_mass_malignant_median</td>\n",
       "      <td>0.004178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>CC_1_pectoral muscle_sum</td>\n",
       "      <td>0.003234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>square_MLO_1_lymphonodus_sum</td>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>another_CC_1_fibrocystic_breast_changes_count</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            feature  importance\n",
       "1154        prob_square_MLO_1_calcinates_benign_max    0.719360\n",
       "737              square_MLO_1_calcinates_benign_sum    0.716224\n",
       "3                      cancer_probability_predicted    0.698121\n",
       "1083         prob_square_CC_3_calcinates_benign_min    0.584782\n",
       "388                        MLO_2_mass_malignant_min    0.569182\n",
       "...                                             ...         ...\n",
       "51                           CC_1_mass_benign_count    0.004604\n",
       "761              square_MLO_1_mass_malignant_median    0.004178\n",
       "74                         CC_1_pectoral muscle_sum    0.003234\n",
       "752                    square_MLO_1_lymphonodus_sum    0.001858\n",
       "1386  another_CC_1_fibrocystic_breast_changes_count    0.001134\n",
       "\n",
       "[752 rows x 2 columns]"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[feature_importance.importance > 0.0001].sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_type(feature):\n",
    "    \n",
    "    if 'square' in feature:\n",
    "        return 'square'\n",
    "    elif 'prob_square'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance['agg'] = feature_importance.feature.apply(lambda x: x.split('_')[-1])\n",
    "feature_importance['type'] = feature_importance.feature.apply(lambda x: feature_type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance.sort_values('importance', ascending=False).iloc[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feat = X[feature_importance[feature_importance.importance > 0.0001].feature.values]\n",
    "y_feat = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_feat, y_feat, stratify=y_feat, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.110686\n",
      "0:\tlearn: 1.4641425\ttest: 1.4705180\tbest: 1.4705180 (0)\ttotal: 261ms\tremaining: 4m 20s\n",
      "100:\tlearn: 0.5180438\ttest: 0.7306986\tbest: 0.7297976 (98)\ttotal: 12.7s\tremaining: 1m 53s\n",
      "200:\tlearn: 0.3542670\ttest: 0.7336471\tbest: 0.7277790 (115)\ttotal: 25.6s\tremaining: 1m 41s\n",
      "300:\tlearn: 0.2518778\ttest: 0.7358142\tbest: 0.7277790 (115)\ttotal: 37.3s\tremaining: 1m 26s\n",
      "Stopped by overfitting detector  (250 iterations wait)\n",
      "\n",
      "bestTest = 0.7277789616\n",
      "bestIteration = 115\n",
      "\n",
      "Shrink model to first 116 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1b408fe50>"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(loss_function='MultiClass', early_stopping_rounds=250, verbose=100)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = []\n",
    "\n",
    "# for train_index, test_index in StratifiedKFold(n_splits=5).split(X, y):\n",
    "    \n",
    "#     X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    \n",
    "#     X_val, y_val = X.iloc[test_index], y.iloc[test_index]\n",
    "    \n",
    "#     model = CatBoostClassifier(loss_function='MultiClass',\n",
    "#                                early_stopping_rounds=250,\n",
    "#                                verbose=False)\n",
    "\n",
    "#     model.fit(X_train, y_train, eval_set=(X_val, y_val),\n",
    "# #               cat_features=['laterality']\n",
    "#              )\n",
    "    \n",
    "#     print(calculate_metrics(y_val, model.predict(X_val)))\n",
    "    \n",
    "#     models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = np.zeros((df_test.shape[0], 5))\n",
    "\n",
    "# for model in models:\n",
    "#     preds += model.predict_proba(df_test[feature_importance[feature_importance.importance > 0.05].feature.values]) / len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(df_test[feature_importance[feature_importance.importance > 0.0001].feature.values])\n",
    "\n",
    "preds_ = []\n",
    "\n",
    "for pred in preds:\n",
    "    \n",
    "    max_pred = np.where(pred == pred.max())[0][0]\n",
    "    \n",
    "    if pred[4] > 0.005:\n",
    "        preds_.append(5)\n",
    "    \n",
    "    elif pred[3] > 0.01:\n",
    "        preds_.append(4)\n",
    "    \n",
    "    elif pred[2] > 0.015:\n",
    "        preds_.append(3)\n",
    "    \n",
    "    else:\n",
    "        preds_.append(max_pred+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub['BiRads'] = preds_\n",
    "sub['BiRads'] = preds_\n",
    "sub['best'] = pd.read_csv('sub_18.csv')['BiRads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiRads\n",
       "1     795\n",
       "2    1001\n",
       "3    1362\n",
       "4    1278\n",
       "5     227\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.groupby('BiRads').id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best\n",
       "1     937\n",
       "2    1175\n",
       "3    1034\n",
       "4    1303\n",
       "5     214\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.groupby('best').id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id', 'BiRads']].to_csv('sub_30.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BiRads</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8097d218-2c51-4ec8-9ee8-ea6b7701ef3c</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4c9a6bed-a454-467c-b51e-451f5ee2db35</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>f572edaa-93ce-4489-80e2-0fad155e5851</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6aba217f-bbaf-4368-9b30-64b481177c80</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9a13ff22-f414-457b-8e01-e11adea327a9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4653</th>\n",
       "      <td>a71181a4-a11f-49cb-b997-bacbc65123f3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>a83040a4-6949-4915-a863-1a185de4551a</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658</th>\n",
       "      <td>67db950f-8a39-4594-82a4-6b22db8afb76</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660</th>\n",
       "      <td>eb0a4b02-1d68-4b62-bcaa-1825ce5804d2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>061be2ba-9c5d-4c19-815c-deb227a9cc68</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  BiRads  best\n",
       "0     8097d218-2c51-4ec8-9ee8-ea6b7701ef3c       3     4\n",
       "1     4c9a6bed-a454-467c-b51e-451f5ee2db35       4     3\n",
       "7     f572edaa-93ce-4489-80e2-0fad155e5851       2     1\n",
       "9     6aba217f-bbaf-4368-9b30-64b481177c80       4     3\n",
       "10    9a13ff22-f414-457b-8e01-e11adea327a9       3     4\n",
       "...                                    ...     ...   ...\n",
       "4653  a71181a4-a11f-49cb-b997-bacbc65123f3       3     4\n",
       "4656  a83040a4-6949-4915-a863-1a185de4551a       3     2\n",
       "4658  67db950f-8a39-4594-82a4-6b22db8afb76       4     5\n",
       "4660  eb0a4b02-1d68-4b62-bcaa-1825ce5804d2       3     4\n",
       "4661  061be2ba-9c5d-4c19-815c-deb227a9cc68       1     3\n",
       "\n",
       "[2031 rows x 3 columns]"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.BiRads != sub.best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress = [0.2661, 0.1815, 0.2104, 0.2241, \n",
    "        0.2009, 0.2309, 0.2031, 0.2043]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros((sub.shape[0], 5))\n",
    "\n",
    "for i in range(18, 25):\n",
    "\n",
    "    pred_temp = pd.read_csv('sub_{}.csv'.format(i))['BiRads']\n",
    "    sub[i] = pred_temp\n",
    "    \n",
    "#     for j, pr in enumerate(pred_temp):\n",
    "        \n",
    "#         preds[j, pr-1] += ress[i-11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[(sub[18] == sub[19])&(sub[18] == sub[20])\n",
    "    &(sub[18] == sub[21])&(sub[18] == sub[22])\n",
    "    &(sub[18] == sub[23])&(sub[18] == sub[24])][['id', 'BiRads']].to_csv('train_from_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = []\n",
    "\n",
    "for pred in preds:\n",
    "    \n",
    "    preds_.append(np.where(pred == pred.max())[0][0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['BiRads'] = preds_\n",
    "sub['best'] = pd.read_csv('sub_18.csv')['BiRads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>BiRads</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8097d218-2c51-4ec8-9ee8-ea6b7701ef3c</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4c9a6bed-a454-467c-b51e-451f5ee2db35</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2737373f-e0ce-4d58-8d0a-0b85925d1783</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6aba217f-bbaf-4368-9b30-64b481177c80</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>d3b1b825-ea24-4366-afe2-d69b8455f981</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>be19bb09-a4f3-4d81-abf9-d037e5749380</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>7a78f147-851a-472e-b447-7a5add369557</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>a83040a4-6949-4915-a863-1a185de4551a</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4661</th>\n",
       "      <td>061be2ba-9c5d-4c19-815c-deb227a9cc68</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>667ccd8d-51dd-4f32-9c6f-5883b7dee573</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  BiRads  best\n",
       "0     8097d218-2c51-4ec8-9ee8-ea6b7701ef3c       2     4\n",
       "1     4c9a6bed-a454-467c-b51e-451f5ee2db35       4     3\n",
       "2     2737373f-e0ce-4d58-8d0a-0b85925d1783       4     3\n",
       "9     6aba217f-bbaf-4368-9b30-64b481177c80       4     3\n",
       "14    d3b1b825-ea24-4366-afe2-d69b8455f981       3     2\n",
       "...                                    ...     ...   ...\n",
       "4651  be19bb09-a4f3-4d81-abf9-d037e5749380       3     2\n",
       "4652  7a78f147-851a-472e-b447-7a5add369557       1     3\n",
       "4656  a83040a4-6949-4915-a863-1a185de4551a       1     2\n",
       "4661  061be2ba-9c5d-4c19-815c-deb227a9cc68       1     3\n",
       "4662  667ccd8d-51dd-4f32-9c6f-5883b7dee573       5     4\n",
       "\n",
       "[1131 rows x 3 columns]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[sub.BiRads != sub.best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[['id', 'BiRads']].to_csv('sub_27.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
